{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "mx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_LOCATION = '../data/raw/35.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGINNING\n",
      " The Time Machine, by H. G. Wells [1898]\n",
      "\n",
      "\n",
      "\n",
      "I\n",
      "\n",
      "\n",
      "The Time Traveller (for so it will be convenient to speak of him)\n",
      "was expounding a recondite matter to us. His grey eyes shone and\n",
      "twinkled, and his usually pale face was flushed and animated. The\n",
      "fire burned brightly, and the soft radiance of the incandescent\n",
      "lights in the lilies of silver caught the bubbles that flashed and\n",
      "passed in our glasses. Our chairs, being his patents, embraced and\n",
      "caressed us rather than submitted to be sat upon, and there was that\n",
      "luxurious after-dinner atmosphere when thought roams gracefully\n",
      "free of the trammels of precision. And he put it to us in this\n",
      "way--marking the points with a lean forefinger--as we sat and lazily\n",
      "admired his earnestness over this new paradox (as we thought it)\n",
      "and his fecundity.\n",
      "\n",
      "'You must follow me carefully. I shall have to controvert one or two\n",
      "ideas that are almost universally accepted. The geometry, for\n",
      "instance, they taught you at school is founded on a misconception.'\n",
      "\n",
      "'Is not \n",
      "\n",
      "END\n",
      "  but with the riddles of our own time answered and its wearisome\n",
      "problems solved? Into the manhood of the race: for I, for my own\n",
      "part, cannot think that these latter days of weak experiment,\n",
      "fragmentary theory, and mutual discord are indeed man's culminating\n",
      "time! I say, for my own part. He, I know--for the question had been\n",
      "discussed among us long before the Time Machine was made--thought\n",
      "but cheerlessly of the Advancement of Mankind, and saw in the\n",
      "growing pile of civilization only a foolish heaping that must\n",
      "inevitably fall back upon and destroy its makers in the end. If that\n",
      "is so, it remains for us to live as though it were not so. But to me\n",
      "the future is still black and blank--is a vast ignorance, lit at a\n",
      "few casual places by the memory of his story. And I have by me, for\n",
      "my comfort, two strange white flowers--shrivelled now, and brown and\n",
      "flat and brittle--to witness that even when mind and strength had\n",
      "gone, gratitude and a mutual tenderness still lived on in the heart\n",
      "of man\n"
     ]
    }
   ],
   "source": [
    "with open(RAW_DATA_LOCATION) as f:\n",
    "    raw_data = f.read()\n",
    "raw_data = raw_data[44332: -24182]\n",
    "print('\\nBEGINNING\\n', raw_data[:1000])\n",
    "print( '\\nEND\\n', raw_data[-1000:])\n",
    "#raw_data_val = raw_data[-len(raw_data)//3:]\n",
    "#raw_data = raw_data[:2*len(raw_data)//3]\n",
    "#print(len(raw_data), len(raw_data_val), len(raw_data[:2*len(raw_data)//3]))\n",
    "#print( '\\n\\n\\n\\n\\n\\n', len(raw_data), len(raw_data_val), '\\n\\n\\n\\n\\n\\n')\n",
    "#print(raw_data[-100:], '\\n\\n\\n\\n\\n\\n' + raw_data_val[-100:])\n",
    "\n",
    "with open('../data/raw/train_data.txt', 'w+') as output_file:\n",
    "    output_file.write(raw_data)\n",
    "    \n",
    "#with open('../data/raw/test_data.txt', 'w+') as output_file:\n",
    " #   output_file.write(raw_data_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import numpy as np\n",
    "from mxnet import gluon, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register(segment=['train', 'val', 'test'])\n",
    "class TimeMachineDataSet(_WikiText):\n",
    "    \"\"\"WikiText-2 word-level dataset for language modeling, from Salesforce research.\n",
    "\n",
    "    From\n",
    "    https://einstein.ai/research/the-wikitext-long-term-dependency-language-modeling-dataset\n",
    "\n",
    "    License: Creative Commons Attribution-ShareAlike\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    segment : {'train', 'val', 'test'}, default 'train'\n",
    "        Dataset segment.\n",
    "    skip_empty : bool, default True\n",
    "        Whether to skip the empty samples produced from sample_splitters. If False, `bos` and `eos`\n",
    "        will be added in empty samples.\n",
    "    tokenizer : function, default str.split\n",
    "        A function that splits each sample string into list of tokens.\n",
    "    bos : str or None, default None\n",
    "        The token to add at the begining of each sentence. If None, nothing is added.\n",
    "    eos : str or None, default '<eos>'\n",
    "        The token to add at the end of each sentence. If None, nothing is added.\n",
    "    root : str, default '$MXNET_HOME/datasets/wikitext-2'\n",
    "        Path to temp folder for storing data.\n",
    "        MXNET_HOME defaults to '~/.mxnet'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment='train', skip_empty=True,\n",
    "                 tokenizer=lambda s: s.split(),\n",
    "                 bos=None, eos=C.EOS_TOKEN, root=os.path.join(\n",
    "                     _get_home_dir(), 'datasets', 'wikitext-2'), **kwargs):\n",
    "        self._archive_file = ('wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n",
    "        self._data_file = {'train': ('wiki.train.tokens',\n",
    "                                     '863f29c46ef9d167fff4940ec821195882fe29d1'),\n",
    "                           'val': ('wiki.valid.tokens',\n",
    "                                   '0418625c8b4da6e4b5c7a0b9e78d4ae8f7ee5422'),\n",
    "                           'test': ('wiki.test.tokens',\n",
    "                                    'c7b8ce0aa086fb34dab808c5c49224211eb2b172')}\n",
    "        super(WikiText2,\n",
    "              self).__init__('wikitext-2', segment, bos, eos, skip_empty, root,\n",
    "                             tokenizer=tokenizer, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = nlp.data.LanguageModelDataset('../data/raw/train_data.txt')\n",
    "train_data_iter = gluon.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Time',\n",
       " 'Machine,',\n",
       " 'by',\n",
       " 'H.',\n",
       " 'G.',\n",
       " 'Wells',\n",
       " '[1898]',\n",
       " 'I',\n",
       " 'The',\n",
       " 'Time',\n",
       " 'Traveller',\n",
       " '(for',\n",
       " 'so',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'convenient',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'of',\n",
       " 'him)',\n",
       " 'was',\n",
       " 'expounding',\n",
       " 'a',\n",
       " 'recondite',\n",
       " 'matter',\n",
       " 'to',\n",
       " 'us.',\n",
       " 'His',\n",
       " 'grey',\n",
       " 'eyes',\n",
       " 'shone',\n",
       " 'and',\n",
       " 'twinkled,',\n",
       " 'and',\n",
       " 'his',\n",
       " 'usually',\n",
       " 'pale',\n",
       " 'face',\n",
       " 'was',\n",
       " 'flushed',\n",
       " 'and',\n",
       " 'animated.',\n",
       " 'The',\n",
       " 'fire',\n",
       " 'burned',\n",
       " 'brightly,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'soft',\n",
       " 'radiance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'incandescent',\n",
       " 'lights',\n",
       " 'in',\n",
       " 'the',\n",
       " 'lilies',\n",
       " 'of',\n",
       " 'silver',\n",
       " 'caught',\n",
       " 'the',\n",
       " 'bubbles',\n",
       " 'that',\n",
       " 'flashed',\n",
       " 'and',\n",
       " 'passed',\n",
       " 'in',\n",
       " 'our',\n",
       " 'glasses.',\n",
       " 'Our',\n",
       " 'chairs,',\n",
       " 'being',\n",
       " 'his',\n",
       " 'patents,',\n",
       " 'embraced',\n",
       " 'and',\n",
       " 'caressed',\n",
       " 'us',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'submitted',\n",
       " 'to',\n",
       " 'be',\n",
       " 'sat',\n",
       " 'upon,',\n",
       " 'and',\n",
       " 'there',\n",
       " 'was',\n",
       " 'that',\n",
       " 'luxurious',\n",
       " 'after-dinner',\n",
       " 'atmosphere',\n",
       " 'when',\n",
       " 'thought',\n",
       " 'roams',\n",
       " 'gracefully',\n",
       " 'free',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trammels',\n",
       " 'of',\n",
       " 'precision.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'us',\n",
       " 'in',\n",
       " 'this',\n",
       " 'way--marking',\n",
       " 'the',\n",
       " 'points',\n",
       " 'with',\n",
       " 'a',\n",
       " 'lean',\n",
       " 'forefinger--as',\n",
       " 'we',\n",
       " 'sat',\n",
       " 'and',\n",
       " 'lazily',\n",
       " 'admired',\n",
       " 'his',\n",
       " 'earnestness',\n",
       " 'over',\n",
       " 'this',\n",
       " 'new',\n",
       " 'paradox',\n",
       " '(as',\n",
       " 'we',\n",
       " 'thought',\n",
       " 'it)',\n",
       " 'and',\n",
       " 'his',\n",
       " 'fecundity.',\n",
       " \"'You\",\n",
       " 'must',\n",
       " 'follow',\n",
       " 'me',\n",
       " 'carefully.',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'have',\n",
       " 'to',\n",
       " 'controvert',\n",
       " 'one',\n",
       " 'or',\n",
       " 'two',\n",
       " 'ideas',\n",
       " 'that',\n",
       " 'are',\n",
       " 'almost',\n",
       " 'universally',\n",
       " 'accepted.',\n",
       " 'The',\n",
       " 'geometry,',\n",
       " 'for',\n",
       " 'instance,',\n",
       " 'they',\n",
       " 'taught',\n",
       " 'you',\n",
       " 'at',\n",
       " 'school',\n",
       " 'is',\n",
       " 'founded',\n",
       " 'on',\n",
       " 'a',\n",
       " \"misconception.'\",\n",
       " \"'Is\",\n",
       " 'not',\n",
       " 'that',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'large',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'expect',\n",
       " 'us',\n",
       " 'to',\n",
       " 'begin',\n",
       " \"upon?'\",\n",
       " 'said',\n",
       " 'Filby,',\n",
       " 'an',\n",
       " 'argumentative',\n",
       " 'person',\n",
       " 'with',\n",
       " 'red',\n",
       " 'hair.',\n",
       " \"'I\",\n",
       " 'do',\n",
       " 'not',\n",
       " 'mean',\n",
       " 'to',\n",
       " 'ask',\n",
       " 'you',\n",
       " 'to',\n",
       " 'accept',\n",
       " 'anything',\n",
       " 'without',\n",
       " 'reasonable',\n",
       " 'ground',\n",
       " 'for',\n",
       " 'it.',\n",
       " 'You',\n",
       " 'will',\n",
       " 'soon',\n",
       " 'admit',\n",
       " 'as',\n",
       " 'much',\n",
       " 'as',\n",
       " 'I',\n",
       " 'need',\n",
       " 'from',\n",
       " 'you.',\n",
       " 'You',\n",
       " 'know',\n",
       " 'of',\n",
       " 'course',\n",
       " 'that',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'line,',\n",
       " 'a',\n",
       " 'line',\n",
       " 'of',\n",
       " 'thickness',\n",
       " '_nil_,',\n",
       " 'has',\n",
       " 'no',\n",
       " 'real',\n",
       " 'existence.',\n",
       " 'They',\n",
       " 'taught',\n",
       " 'you',\n",
       " 'that?',\n",
       " 'Neither',\n",
       " 'has',\n",
       " 'a',\n",
       " 'mathematical',\n",
       " 'plane.',\n",
       " 'These',\n",
       " 'things',\n",
       " 'are',\n",
       " 'mere',\n",
       " \"abstractions.'\",\n",
       " \"'That\",\n",
       " 'is',\n",
       " 'all',\n",
       " \"right,'\",\n",
       " 'said',\n",
       " 'the',\n",
       " 'Psychologist.',\n",
       " \"'Nor,\",\n",
       " 'having',\n",
       " 'only',\n",
       " 'length,',\n",
       " 'breadth,',\n",
       " 'and',\n",
       " 'thickness,',\n",
       " 'can',\n",
       " 'a',\n",
       " 'cube',\n",
       " 'have',\n",
       " 'a',\n",
       " 'real',\n",
       " \"existence.'\",\n",
       " \"'There\",\n",
       " 'I',\n",
       " \"object,'\",\n",
       " 'said',\n",
       " 'Filby.',\n",
       " \"'Of\",\n",
       " 'course',\n",
       " 'a',\n",
       " 'solid',\n",
       " 'body',\n",
       " 'may',\n",
       " 'exist.',\n",
       " 'All',\n",
       " 'real',\n",
       " \"things--'\",\n",
       " \"'So\",\n",
       " 'most',\n",
       " 'people',\n",
       " 'think.',\n",
       " 'But',\n",
       " 'wait',\n",
       " 'a',\n",
       " 'moment.',\n",
       " 'Can',\n",
       " 'an',\n",
       " '_instantaneous_',\n",
       " 'cube',\n",
       " \"exist?'\",\n",
       " \"'Don't\",\n",
       " 'follow',\n",
       " \"you,'\",\n",
       " 'said',\n",
       " 'Filby.',\n",
       " \"'Can\",\n",
       " 'a',\n",
       " 'cube',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'last',\n",
       " 'for',\n",
       " 'any',\n",
       " 'time',\n",
       " 'at',\n",
       " 'all,',\n",
       " 'have',\n",
       " 'a',\n",
       " 'real',\n",
       " \"existence?'\",\n",
       " 'Filby',\n",
       " 'became',\n",
       " 'pensive.',\n",
       " \"'Clearly,'\",\n",
       " 'the',\n",
       " 'Time',\n",
       " 'Traveller',\n",
       " 'proceeded,',\n",
       " \"'any\",\n",
       " 'real',\n",
       " 'body',\n",
       " 'must',\n",
       " 'have',\n",
       " 'extension',\n",
       " 'in',\n",
       " '_four_',\n",
       " 'directions:',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'Length,',\n",
       " 'Breadth,',\n",
       " 'Thickness,',\n",
       " 'and--Duration.',\n",
       " 'But',\n",
       " 'through',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'infirmity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'flesh,',\n",
       " 'which',\n",
       " 'I',\n",
       " 'will',\n",
       " 'explain',\n",
       " 'to',\n",
       " 'you',\n",
       " 'in',\n",
       " 'a',\n",
       " 'moment,',\n",
       " 'we',\n",
       " 'incline',\n",
       " 'to',\n",
       " 'overlook',\n",
       " 'this',\n",
       " 'fact.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'really',\n",
       " 'four',\n",
       " 'dimensions,',\n",
       " 'three',\n",
       " 'which',\n",
       " 'we',\n",
       " 'call',\n",
       " 'the',\n",
       " 'three',\n",
       " 'planes',\n",
       " 'of',\n",
       " 'Space,',\n",
       " 'and',\n",
       " 'a',\n",
       " 'fourth,',\n",
       " 'Time.',\n",
       " 'There',\n",
       " 'is,',\n",
       " 'however,',\n",
       " 'a',\n",
       " 'tendency',\n",
       " 'to',\n",
       " 'draw',\n",
       " 'an',\n",
       " 'unreal',\n",
       " 'distinction',\n",
       " 'between',\n",
       " 'the',\n",
       " 'former',\n",
       " 'three',\n",
       " 'dimensions',\n",
       " 'and',\n",
       " 'the',\n",
       " 'latter,',\n",
       " 'because',\n",
       " 'it',\n",
       " 'happens',\n",
       " 'that',\n",
       " 'our',\n",
       " 'consciousness',\n",
       " 'moves',\n",
       " 'intermittently',\n",
       " 'in',\n",
       " 'one',\n",
       " 'direction',\n",
       " 'along',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'from',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'our',\n",
       " \"lives.'\",\n",
       " \"'That,'\",\n",
       " 'said',\n",
       " 'a',\n",
       " 'very',\n",
       " 'young',\n",
       " 'man,',\n",
       " 'making',\n",
       " 'spasmodic',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'relight',\n",
       " 'his',\n",
       " 'cigar',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lamp;',\n",
       " \"'that\",\n",
       " '...',\n",
       " 'very',\n",
       " 'clear',\n",
       " \"indeed.'\",\n",
       " \"'Now,\",\n",
       " 'it',\n",
       " 'is',\n",
       " 'very',\n",
       " 'remarkable',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'so',\n",
       " 'extensively',\n",
       " \"overlooked,'\",\n",
       " 'continued',\n",
       " 'the',\n",
       " 'Time',\n",
       " 'Traveller,',\n",
       " 'with',\n",
       " 'a',\n",
       " 'slight',\n",
       " 'accession',\n",
       " 'of',\n",
       " 'cheerfulness.',\n",
       " \"'Really\",\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " 'is',\n",
       " 'meant',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Fourth',\n",
       " 'Dimension,',\n",
       " 'though',\n",
       " 'some',\n",
       " 'people',\n",
       " 'who',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'the',\n",
       " 'Fourth',\n",
       " 'Dimension',\n",
       " 'do',\n",
       " 'not',\n",
       " 'know',\n",
       " 'they',\n",
       " 'mean',\n",
       " 'it.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'only',\n",
       " 'another',\n",
       " 'way',\n",
       " 'of',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'Time.',\n",
       " '_There',\n",
       " 'is',\n",
       " 'no',\n",
       " 'difference',\n",
       " 'between',\n",
       " 'Time',\n",
       " 'and',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'three',\n",
       " 'dimensions',\n",
       " 'of',\n",
       " 'Space',\n",
       " 'except',\n",
       " 'that',\n",
       " 'our',\n",
       " 'consciousness',\n",
       " 'moves',\n",
       " 'along',\n",
       " 'it_.',\n",
       " 'But',\n",
       " 'some',\n",
       " 'foolish',\n",
       " 'people',\n",
       " 'have',\n",
       " 'got',\n",
       " 'hold',\n",
       " 'of',\n",
       " 'the',\n",
       " 'wrong',\n",
       " 'side',\n",
       " 'of',\n",
       " 'that',\n",
       " 'idea.',\n",
       " 'You',\n",
       " 'have',\n",
       " 'all',\n",
       " 'heard',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'to',\n",
       " 'say',\n",
       " 'about',\n",
       " 'this',\n",
       " 'Fourth',\n",
       " \"Dimension?'\",\n",
       " \"'_I_\",\n",
       " 'have',\n",
       " \"not,'\",\n",
       " 'said',\n",
       " 'the',\n",
       " 'Provincial',\n",
       " 'Mayor.',\n",
       " \"'It\",\n",
       " 'is',\n",
       " 'simply',\n",
       " 'this.',\n",
       " 'That',\n",
       " 'Space,',\n",
       " 'as',\n",
       " 'our',\n",
       " 'mathematicians',\n",
       " 'have',\n",
       " 'it,',\n",
       " 'is',\n",
       " 'spoken',\n",
       " 'of',\n",
       " 'as',\n",
       " 'having',\n",
       " 'three',\n",
       " 'dimensions,',\n",
       " 'which',\n",
       " 'one',\n",
       " 'may',\n",
       " 'call',\n",
       " 'Length,',\n",
       " 'Breadth,',\n",
       " 'and',\n",
       " 'Thickness,',\n",
       " 'and',\n",
       " 'is',\n",
       " 'always',\n",
       " 'definable',\n",
       " 'by',\n",
       " 'reference',\n",
       " 'to',\n",
       " 'three',\n",
       " 'planes,',\n",
       " 'each',\n",
       " 'at',\n",
       " 'right',\n",
       " 'angles',\n",
       " 'to',\n",
       " 'the',\n",
       " 'others.',\n",
       " 'But',\n",
       " 'some',\n",
       " 'philosophical',\n",
       " 'people',\n",
       " 'have',\n",
       " 'been',\n",
       " 'asking',\n",
       " 'why',\n",
       " '_three_',\n",
       " 'dimensions',\n",
       " 'particularly--why',\n",
       " 'not',\n",
       " 'another',\n",
       " 'direction',\n",
       " 'at',\n",
       " 'right',\n",
       " 'angles',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'three?--and',\n",
       " 'have',\n",
       " 'even',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'construct',\n",
       " 'a',\n",
       " 'Four-Dimension',\n",
       " 'geometry.',\n",
       " 'Professor',\n",
       " 'Simon',\n",
       " 'Newcomb',\n",
       " 'was',\n",
       " 'expounding',\n",
       " 'this',\n",
       " 'to',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Mathematical',\n",
       " 'Society',\n",
       " 'only',\n",
       " 'a',\n",
       " 'month',\n",
       " 'or',\n",
       " 'so',\n",
       " 'ago.',\n",
       " 'You',\n",
       " 'know',\n",
       " 'how',\n",
       " 'on',\n",
       " 'a',\n",
       " 'flat',\n",
       " 'surface,',\n",
       " 'which',\n",
       " 'has',\n",
       " 'only',\n",
       " 'two',\n",
       " 'dimensions,',\n",
       " 'we',\n",
       " 'can',\n",
       " 'represent',\n",
       " 'a',\n",
       " 'figure',\n",
       " 'of',\n",
       " 'a',\n",
       " 'three-dimensional',\n",
       " 'solid,',\n",
       " 'and',\n",
       " 'similarly',\n",
       " 'they',\n",
       " 'think',\n",
       " 'that',\n",
       " 'by',\n",
       " 'models',\n",
       " 'of',\n",
       " 'three',\n",
       " 'dimensions',\n",
       " 'they',\n",
       " 'could',\n",
       " 'represent',\n",
       " 'one',\n",
       " 'of',\n",
       " 'four--if',\n",
       " 'they',\n",
       " 'could',\n",
       " 'master',\n",
       " 'the',\n",
       " 'perspective',\n",
       " 'of',\n",
       " 'the',\n",
       " 'thing.',\n",
       " \"See?'\",\n",
       " \"'I\",\n",
       " 'think',\n",
       " \"so,'\",\n",
       " 'murmured',\n",
       " 'the',\n",
       " 'Provincial',\n",
       " 'Mayor;',\n",
       " 'and,',\n",
       " 'knitting',\n",
       " 'his',\n",
       " 'brows,',\n",
       " 'he',\n",
       " 'lapsed',\n",
       " 'into',\n",
       " 'an',\n",
       " 'introspective',\n",
       " 'state,',\n",
       " 'his',\n",
       " 'lips',\n",
       " 'moving',\n",
       " 'as',\n",
       " 'one',\n",
       " 'who',\n",
       " 'repeats',\n",
       " 'mystic',\n",
       " 'words.',\n",
       " \"'Yes,\",\n",
       " 'I',\n",
       " 'think',\n",
       " 'I',\n",
       " 'see',\n",
       " 'it',\n",
       " \"now,'\",\n",
       " 'he',\n",
       " 'said',\n",
       " 'after',\n",
       " 'some',\n",
       " 'time,',\n",
       " 'brightening',\n",
       " 'in',\n",
       " 'a',\n",
       " 'quite',\n",
       " 'transitory',\n",
       " 'manner.',\n",
       " \"'Well,\",\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'mind',\n",
       " 'telling',\n",
       " 'you',\n",
       " 'I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'at',\n",
       " 'work',\n",
       " 'upon',\n",
       " 'this',\n",
       " 'geometry',\n",
       " 'of',\n",
       " 'Four',\n",
       " 'Dimensions',\n",
       " 'for',\n",
       " 'some',\n",
       " 'time.',\n",
       " 'Some',\n",
       " 'of',\n",
       " 'my',\n",
       " 'results',\n",
       " 'are',\n",
       " 'curious.',\n",
       " 'For',\n",
       " 'instance,',\n",
       " 'here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'portrait',\n",
       " 'of',\n",
       " 'a',\n",
       " 'man',\n",
       " 'at',\n",
       " 'eight',\n",
       " 'years',\n",
       " 'old,',\n",
       " 'another',\n",
       " 'at',\n",
       " 'fifteen,',\n",
       " 'another',\n",
       " 'at',\n",
       " 'seventeen,',\n",
       " 'another',\n",
       " 'at',\n",
       " 'twenty-three,',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on.',\n",
       " 'All',\n",
       " 'these',\n",
       " 'are',\n",
       " 'evidently',\n",
       " 'sections,',\n",
       " 'as',\n",
       " 'it',\n",
       " 'were,',\n",
       " 'Three-Dimensional',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'his',\n",
       " 'Four-Dimensioned',\n",
       " 'being,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fixed',\n",
       " 'and',\n",
       " 'unalterable',\n",
       " 'thing.',\n",
       " \"'Scientific\",\n",
       " \"people,'\",\n",
       " 'proceeded',\n",
       " 'the',\n",
       " 'Time',\n",
       " 'Traveller,',\n",
       " 'after',\n",
       " 'the',\n",
       " 'pause',\n",
       " 'required',\n",
       " 'for',\n",
       " 'the',\n",
       " 'proper',\n",
       " 'assimilation',\n",
       " 'of',\n",
       " 'this,',\n",
       " \"'know\",\n",
       " 'very',\n",
       " 'well',\n",
       " 'that',\n",
       " 'Time',\n",
       " 'is',\n",
       " 'only',\n",
       " 'a',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'Space.',\n",
       " 'Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'popular',\n",
       " 'scientific',\n",
       " 'diagram,',\n",
       " 'a',\n",
       " 'weather',\n",
       " 'record.',\n",
       " 'This',\n",
       " 'line',\n",
       " 'I',\n",
       " 'trace',\n",
       " 'with',\n",
       " 'my',\n",
       " 'finger',\n",
       " 'shows',\n",
       " 'the',\n",
       " 'movement',\n",
       " 'of',\n",
       " 'the',\n",
       " 'barometer.',\n",
       " 'Yesterday',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'high,',\n",
       " 'yesterday',\n",
       " 'night',\n",
       " 'it',\n",
       " 'fell,',\n",
       " 'then',\n",
       " 'this',\n",
       " 'morning',\n",
       " 'it',\n",
       " 'rose',\n",
       " 'again,',\n",
       " 'and',\n",
       " 'so',\n",
       " 'gently',\n",
       " 'upward',\n",
       " 'to',\n",
       " 'here.',\n",
       " 'Surely',\n",
       " 'the',\n",
       " 'mercury',\n",
       " 'did',\n",
       " 'not',\n",
       " 'trace',\n",
       " 'this',\n",
       " 'line',\n",
       " 'in',\n",
       " 'any',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dimensions',\n",
       " 'of',\n",
       " 'Space',\n",
       " 'generally',\n",
       " 'recognized?',\n",
       " 'But',\n",
       " 'certainly',\n",
       " 'it',\n",
       " 'traced',\n",
       " 'such',\n",
       " 'a',\n",
       " 'line,',\n",
       " 'and',\n",
       " 'that',\n",
       " 'line,',\n",
       " 'therefore,',\n",
       " 'we',\n",
       " 'must',\n",
       " 'conclude',\n",
       " 'was',\n",
       " 'along',\n",
       " 'the',\n",
       " \"Time-Dimension.'\",\n",
       " \"'But,'\",\n",
       " 'said',\n",
       " 'the',\n",
       " 'Medical',\n",
       " 'Man,',\n",
       " 'staring',\n",
       " 'hard',\n",
       " 'at',\n",
       " 'a',\n",
       " 'coal',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fire,',\n",
       " \"'if\",\n",
       " 'Time',\n",
       " 'is',\n",
       " 'really',\n",
       " 'only',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'dimension',\n",
       " 'of',\n",
       " 'Space,',\n",
       " 'why',\n",
       " 'is',\n",
       " 'it,',\n",
       " 'and',\n",
       " 'why',\n",
       " 'has',\n",
       " 'it',\n",
       " 'always',\n",
       " 'been,',\n",
       " 'regarded',\n",
       " 'as',\n",
       " 'something',\n",
       " 'different?',\n",
       " 'And',\n",
       " 'why',\n",
       " 'cannot',\n",
       " 'we',\n",
       " 'move',\n",
       " 'in',\n",
       " 'Time',\n",
       " 'as',\n",
       " 'we',\n",
       " 'move',\n",
       " 'about',\n",
       " 'in',\n",
       " 'the',\n",
       " 'other',\n",
       " 'dimensions',\n",
       " 'of',\n",
       " \"Space?'\",\n",
       " 'The',\n",
       " 'Time',\n",
       " 'Traveller',\n",
       " 'smiled.',\n",
       " \"'Are\",\n",
       " 'you',\n",
       " 'sure',\n",
       " 'we',\n",
       " 'can',\n",
       " 'move',\n",
       " 'freely',\n",
       " 'in',\n",
       " 'Space?',\n",
       " 'Right',\n",
       " 'and',\n",
       " 'left',\n",
       " 'we',\n",
       " 'can',\n",
       " 'go,',\n",
       " 'backward',\n",
       " 'and',\n",
       " 'forward',\n",
       " 'freely',\n",
       " 'enough,',\n",
       " 'and',\n",
       " 'men',\n",
       " 'always',\n",
       " 'have',\n",
       " 'done',\n",
       " 'so.',\n",
       " 'I',\n",
       " 'admit',\n",
       " 'we',\n",
       " 'move',\n",
       " 'freely',\n",
       " ...]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/wikitext-2-v1.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/wikitext-2/wikitext-2-v1.zip...\n"
     ]
    }
   ],
   "source": [
    "num_gpus = 1\n",
    "context = [mx.gpu(i) for i in range(num_gpus)] if num_gpus else [mx.cpu()]\n",
    "log_interval = 200\n",
    "\n",
    "batch_size = 20 * len(context)\n",
    "lr = 20\n",
    "epochs = 3\n",
    "bptt = 35\n",
    "grad_clip = 0.25\n",
    "\n",
    "\n",
    "dataset_name = 'wikitext-2'\n",
    "train_dataset, val_dataset, test_dataset = [nlp.data.WikiText2(segment=segment, \n",
    "                                                               root='../data/', \n",
    "                                                               bos=None, eos='<eos>',\n",
    "                                                               skip_empty=False)\n",
    "                                            for segment in ['train', 'val', 'test']]\n",
    "\n",
    "vocab = nlp.Vocab(nlp.data.Counter(train_dataset[0]), padding_token=None, bos_token=None)\n",
    "\n",
    "train_data, val_data, test_data = [x.bptt_batchify(vocab, bptt, batch_size,\n",
    "                                                   last_batch='discard')\n",
    "                                   for x in [train_dataset, val_dataset, test_dataset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
